https://www.promptingguide.ai/


LLM Settings: 

* Temperature --> Control randomness
* Top P --> High value would enable the model to look at more possible words
* Max Length --> Set the maximum length for the response
* Frequency penalty --> Avoids repeating the same words/tokens
* Presence penalty --> To avoid repeating certain phrases

Elements of a Prompt: A prompt contains any of the following elements:

* Instruction - a specific task or instruction you want the model to perform
* Context - external information or additional context that can steer the model to better responses
* Input Data - the input or question that we are interested to find a response for
* Output Indicator - the type or format of the output.

Prompt Design:
* Start simple
	* Be specific, simple and concise. 
* Iterate over functionality overtime.


Techniques:

* Zero-shot prompting:
	* 